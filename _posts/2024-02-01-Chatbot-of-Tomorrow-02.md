# The Chatbot Architecture of Tomorrow – (2) Limits of Chatbot Cognition

<img src="/docs/assets/img/FOT/LEGO_all_you_need.jpeg" target = "_blank" rel = "noreferrer noopener" alt = "SMBC Sept. 19 2023" width="350"/>

*Is a simple tower of transformer blocks really the best answer?  Image created with DALL·E 3.*

The <a href = "https://landrewwray.github.io/2024/01/31/Chatbot-of-Tomorrow-01.html" target = "_blank" rel = "noreferrer noopener">last post</a> looked at how chatbots work, as well as some of their strengths and weaknesses.  This post will list out key examples of how their limitations stem from architectural choices.  The goal is not to be comprehensive, but rather to quickly illustrate key motivations behind the incoming generation of design innovations -- which will be the subject of the next and final post in this 3-part series.

If any of the terminology seems obscure, it may help to review the introduction to how chatbots work <a href = "https://landrewwray.github.io/2024/01/31/Chatbot-of-Tomorrow-01.html#3-a-quick-review-of-what-chatbots-do" target = "_blank" rel = "noreferrer noopener">at the end of the last post</a>.

**1\.	Each token (word part) gets the same amount of ‘thought’.**  If you ask a 50-layer model for a single-token answer to a question, it must come up with the answer within a single sweep through those 50 transformer layers (or while reading your question).  It cannot pause to think more about the problem.  

**2\.	Tokens are overloaded as RAM.**  This point sounds like the previous one, but there are important distinctions.  The state vector is the same length for each token and helps define the number of truly intelligible ‘words’ that can be encoded at one time.  For example, there’s an estimated limit of <a href = "https://landrewwray.github.io/2023/10/19/Inside-LLaMA-2.html#6-lessons-for-llm-architecture" target = "_blank" rel = "noreferrer noopener">~200 in-memory words</a> within a 4096-long state vector of Llama 2 7B.  For a chatbot to adopt a human-like approach to thinking about chess positions would require that it memorize the current state of the chessboard (around 84 words in an uncompressed representation) as well as possible future positions, which might constitute a significant memory bottleneck.

The per-token allocation of state vectors is a great architectural innovation as far as keeping the model simple and on-task, but it’s also probably the most counterintuitive aspect of how current LLMs process information.

**3\.	Models have no long-term memory.**  The information from each conversation is lost at the start of the next conversation, and the model will only recall information accurately <a href = "https://github.com/gkamradt/LLMTest_NeedleInAHaystack" target = "_blank" rel = "noreferrer noopener">up to a certain prompt length</a>. 

**4\.	Attention layers function as <a href = "https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html" target = "_blank" rel = "noreferrer noopener">pattern matching tools</a>** and can <a href = "https://arxiv.org/abs/2309.01809" target = "_blank" rel = "noreferrer noopener">prime the model</a> for new pattern matching tasks defined in the prompt.  This is great if you want to retrieve and organize information, or to predict the next value in a sequence of numbers, but it’s not necessarily what one wants as a basis of abstract thought.

**5\.	Chatbots are required to overthink things.**  The initial training of chatbots tends to focus on minimizing a metric called ‘perplexity’.  To satisfy this, the chatbot needs to create a list of the possible next tokens (word-parts) and assign them accurate probabilities based on the text the model is trained on [answer1, probability1; answer2, probability2; …].  So, if the prompt is an equation like “1 + (-1) = ”, the correct answer is “0”, but optimal output for the chatbot might be something like [“0”, 65%; “2”, 20%; “?”, 5%; …], based on the frequency with which similar correct and incorrect answers show up in training data scraped from the internet.  This creates a tendency to look at problems from every possible angle at the same time, rather than coherently following a single train of thought.

**6\.	Chatbots are energy-inefficient problem solvers.**  Chatbots are the ultimate ‘high level programming language’ – a software tool that goes to the extreme in sacrificing computational efficiency for versatility.  Their broader incorporation in day-to-day life, from search engines to virtual assistants, may notably increase global energy consumption.

**7\.	Chatbots will face regulatory scrutiny** (policy architecture!).  Human-like AI is the Godzilla of disruptive innovation.  For all the potential that chatbot-powered tools have to improve our lives, they are also a profound shock to the job market.  A recent survey at Davos suggested that ~2% (<a href = "https://futurism.com/the-byte/ceos-layoffs-ai-2024-davos" target = "_blank" rel = "noreferrer noopener">more than 0.25*0.05</a>) of jobs could be cut in 2024 due to AI.  The next five years may see a tumultuous evolution of <a href = "https://www.whitehouse.gov/ostp/ai-bill-of-rights/" target = "_blank" rel = "noreferrer noopener">AI related rights</a> and <a href = "https://www.europarl.europa.eu/news/en/headlines/society/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence" target = "_blank" rel = "noreferrer noopener">regulations</a> featuring <a href = "https://www.wbaltv.com/article/musicians-union-prepared-strike-ai-protections-streaming-residuals/46471224" target = "_blank" rel = "noreferrer noopener">organized labor protests</a>, capital supported counter-movements, and a struggle for the soul of the pro-equity movement – all colored by evergreen angles of politics, national security, and international jockying.


